<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.68.3" />


<title>Efficient Markov Chain Monte Carlo in R with Rcpp - Bayesian Statistics and Functional Programming </title>
<meta property="og:title" content="Efficient Markov Chain Monte Carlo in R with Rcpp - Bayesian Statistics and Functional Programming ">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/tomorrow-night-eighties.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/picture_cropped.jpg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/blog/">Blog</a></li>
    
    <li><a href="https://github.com/jonnylaw">GitHub</a></li>
    
    <li><a href="https://twitter.com/lawsy">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    <h1 class="article-title">Efficient Markov Chain Monte Carlo in R with Rcpp</h1>

    

    <div class="article-content">
      


<div id="bivariate-normal-model" class="section level1">
<h1>Bivariate Normal Model</h1>
<p>This post considers how to implement a simple Metropolis scheme to determine the parameter posterior distribution of a bivariate Normal distribution. The implementation is generic, using higher-order-functions and hence can be re-used with new algorithms by specifying the un-normalised log-posterior density and a proposal distribution for the parameters. The built-in <code>parallel</code> package is used fit multiple chains in parallel, finally the Metropolis algorithm is reimplemented in C++ using Rcpp which seemlessly integrates with R.</p>
<pre class="r"><code>bivariate_normal &lt;- function(theta, n) {
  mu1 &lt;- theta[1]
  sigma1 &lt;- theta[2]
  mu2 &lt;- theta[3]
  sigma2 &lt;- theta[4]
  x &lt;- rnorm(n / 2, mean = mu1, sd = sigma1)
  y &lt;- rnorm(n / 2, mean = mu2, sd = sigma2)
  tibble(x, y)
}

theta &lt;- c(5.0, 0.5, 2.0, 1.5)
sims &lt;- bivariate_normal(theta, 1000)
xs &lt;- as.matrix(sims)
ggplot(sims, aes(x, y)) + 
  geom_point()</code></pre>
<p><img src="/blog/metropolis_r_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The random variables in the model can be written as:</p>
<p><span class="math display">\[p(y,\mu, \Sigma) = p(\mu)p(\Sigma)\prod_{i=1}^N\mathcal{N}(y_i;\mu, \Sigma)\]</span></p>
<p>The covariance matrix is diagonal, hence the log-likelihood can be written as the sum of two univariate normal distributions:</p>
<p><span class="math display">\[\log p(y|\mu, \Sigma) = \sum_{j=1}^2\left(-\frac{N}{2}\log(2\pi\sigma_j^2) - \frac{1}{2\sigma_j^2}\sum_{i=1}^N(y_{ij}-\mu_j)^2\right)\]</span></p>
<pre class="r"><code>log_likelihood &lt;- function(xs, theta) {
  apply(xs, 1, function(x) dnorm(x[1], mean = theta[1], sd = theta[2], log = T) + 
          dnorm(x[2], mean = theta[3], sd = theta[4], log = T)) %&gt;% sum()
}</code></pre>
<p>The prior distributions are chosen to be:</p>
<p><span class="math display">\[\begin{align}
p(\mu_j) &amp;= \mathcal{N}(0, 3), \\
p(\Sigma_{jj}) &amp;= \textrm{Gamma}(3, 3), \quad j = 1, 2.
\end{align}\]</span></p>
<pre class="r"><code>log_prior &lt;- function(theta) {
  dnorm(theta[1], log = T) + 
    dnorm(theta[3], log = T) + 
    dgamma(theta[2], shape = 3.0, rate = 3.0, log = T) + 
    dgamma(theta[4], shape = 3.0, rate = 3.0, log = T)
}
log_posterior &lt;- function(xs) 
  function(theta) 
    log_likelihood(xs, theta) + log_prior(theta)</code></pre>
</div>
<div id="metropolis-hastings-algorithm" class="section level1">
<h1>Metropolis-Hastings algorithm</h1>
<p>A <a href="https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm">Metropolis-Hastings</a> algorithm can be used to determine the posterior distribution of the parameters, <span class="math inline">\(theta = \{\mu, \Sigma\}\)</span>. The Metropolis algorithm constructs a Markov chain whose stationary distribution corresponds to the target posterior distribution, <span class="math inline">\(p(\theta|y)\)</span>. In order to construct the Markov chain with this property, a carefully chosen tansition function <span class="math inline">\(P(\theta^\prime|\theta)\)</span> is used. In order to prove the Metropolis algorithm has the target distribution as its stationary distribution, the existence and uniqueness of the stationary distribution must be determined. A transition function which satisfies detailed balance is chosen which is a sufficient condition for the existence of the stationary distribution:</p>
<p><span class="math display">\[P(\theta^\prime|\theta)p(\theta|y) = P(\theta|\theta^\prime)p(\theta^\prime|y)\]</span></p>
<p>The Markov chain proceeds by proposing a new value of the parameters, <span class="math inline">\(\theta^\prime\)</span> from a distribution which can be easily simulated from (typically a Normal distribution centred at the previously accepted value of the parameter, <span class="math inline">\(\theta\)</span>), <span class="math inline">\(q(\theta^\prime|\theta)\)</span>. The transition function is the product of the proposal distribution and the acceptance ratio. The acceptance ration which satisfies detailed balance is called the Metropolis choice:</p>
<p><span class="math display">\[A = \operatorname{min}\left(1, \frac{p(\theta^\prime|y)q(\theta|\theta^\prime)}{p(\theta|y)q(\theta^\prime|\theta)}\right).\]</span></p>
</div>
<div id="r-implementation" class="section level1">
<h1>R Implementation</h1>
<p>First of a single step of the Metropolis algorithm is implementated. This is a higher order function, since two of the arguments are functions themselves. The function <code>log_posterior</code> is a function from parameters to log-likelihood and the <code>proposal</code> is a symmetric proposal distribution for the parameters, a function from parameters to parameters. The final argument, <code>theta</code> represents the parameters.</p>
<pre class="r"><code>metropolis_step &lt;- function(theta, log_posterior, proposal) {
  propTheta &lt;- proposal(theta)
  a &lt;- log_posterior(propTheta) - log_posterior(theta)
  u &lt;- runif(1)
  if (log(u) &lt; a) {
    propTheta
  } else {
    theta
  }
}</code></pre>
<p>Next the step function can be used in a for loop to generate m samples, each dependent on the previous step. An matrix containing <span class="math inline">\(m\)</span> rows is initialised to contain each iteration of the Metropolis algorithm.</p>
<pre class="r"><code>metropolis &lt;- function(theta, log_posterior, proposal, m) {
  out = matrix(NA_real_, nrow = m, ncol = length(theta))
  out[1, ] = theta
  for (i in 2:m) {
    out[i, ] &lt;- metropolis_step(out[i-1, ], log_posterior, proposal)
  }
  out
}</code></pre>
<p>The strictly positive variance parameters are proposed on the log-scale:</p>
<pre class="r"><code>proposal &lt;- function(x) {
  z = rnorm(4, sd = 0.05)
  c(x[1] + z[1], x[2] * exp(z[2]),
    x[3] + z[3], x[4] * exp(z[4]))
}</code></pre>
<p>Finally, all the components are there to sample from the posterior distribution of the parameters. The mean of the sampled posterior distribution should coincide with the parameters used to simulate the data. In the figure below the actual values used to simulate the data are plotted with dashed lines.</p>
<pre class="r"><code>out = metropolis(theta, log_posterior(xs), proposal, 10000)</code></pre>
<p><img src="/blog/metropolis_r_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="parallel-chains-in-r" class="section level1">
<h1>Parallel Chains in R</h1>
<p>Typically, multiple chains are run in parallel, a straightforward way to do this in R is to use a parallel map from the <a href="https://davisvaughan.github.io/furrr/">furrr</a> package. First we create a new function which alters the <code>metropolis</code> function to return a dataframe:</p>
<pre class="r"><code>metropolis_df &lt;- function(theta, log_posterior, proposal, m, parameter_names) {
  function(x) {
    mat &lt;- metropolis(theta, log_posterior, proposal, m)
    colnames(mat) &lt;- parameter_names
    as.data.frame(mat)
  }
}</code></pre>
<p>Then <code>future_map_dfr</code> is used which performs the function <code>.f</code> for each element of <code>.x</code>. It then rowbinds into a dataframe. This is explicit in the function name, the suffix <code>_dfr</code> meaning a dataframe is the return type and is created by rowbinding the results. The <code>id</code> of each function run is provided by the <code>.id</code> column and takes on the values of <code>.x</code>.</p>
<pre class="r"><code>plan(multiprocess)
mh_samples &lt;- future_map_dfr(
  .x = 1:2,
  .f = metropolis_df(theta, log_posterior(xs), proposal, 10000, actual_values$parameter),
  .id = &quot;chain&quot;
)</code></pre>
<p>The figure below shows the trace plots and marginal densities from 10,000 draws of the parallel Metropolis hastings algorithm.</p>
<p><img src="/blog/metropolis_r_files/figure-html/parallel-diagnostics-1.png" width="672" /></p>
</div>
<div id="rcpp-implementation" class="section level1">
<h1>Rcpp implementation</h1>
<p>R has a straightforward interface to C++, the Metropolis-Hastings algorithm can be re-implemented using C++. C++ is a statically typed imperative language, hopefully the effort of reimplementing in C++ will result in a significant speed-up. The <code>log_posterior</code> and <code>proposal</code> functions are run many times to calculate the Markov chain. Let’s first implement these two functions using C++:</p>
<pre class="cpp"><code>#include &lt;Rcpp.h&gt;
using namespace Rcpp;
// [[Rcpp::plugins(cpp11)]]

// [[Rcpp::export]]
double logDensity(NumericMatrix ys, NumericVector p) {
  double ll = 0;
  int n = ys.nrow();
  for (int i = 0; i &lt; n; i++) {
    ll += R::dnorm(ys(i, 0), p(0), p(1), true) + R::dnorm(ys(i, 1), p(2), p(3), true);
  }
  return ll;
}

// [[Rcpp::export]]
NumericVector proposalCpp(NumericVector p, double delta) {
  int d = p.size();
  NumericVector z(d);
  NumericVector propP(d);
  for (int i = 0; i &lt; d; i++) {
    propP(i) = p(i);
    z(i) = R::rnorm(0, delta);
  }
  propP(0) += z(0);
  propP(1) *= exp(z(1));
  propP(2) += z(2);
  propP(3) *= exp(z(3));
  return propP;
}</code></pre>
<p>These functions can then be used in the Metropolis algorithm written using R, as we can see from the below code chunk the C++ function appears as if it was an R function.</p>
<pre class="r"><code>out_cpp &lt;- metropolis(theta, function(p) logDensity(xs, p), function(p) proposalCpp(p, 0.05), 10000)</code></pre>
<p><img src="/blog/metropolis_r_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="performance-improvements" class="section level1">
<h1>Performance Improvements</h1>
<p>But what about the performance, the relative speedup can be calculated using the <a href="https://github.com/joshuaulrich/microbenchmark/">microbenchmark</a> package. The relative speedup of the C++ method used to generate 100 correlated samples from the posterior distribution is plotted below.</p>
<pre class="r"><code>timings &lt;- microbenchmark(metropolis(theta, log_posterior(xs), proposal, 100), 
                          metropolis(theta, function(p) logDensity(xs, p), 
                                     function(p) proposalCpp(p, 0.05), 100), times = 500)</code></pre>
<p><img src="/blog/metropolis_r_files/figure-html/relative-speedup-1.png" width="672" /></p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/scala.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

